= Architectural Design Patterns
Daniel Hinojosa
:source-highlighter: pygments
:pygments-style: friendly
:icons: font
:imagesdir: ./images
:project-name: advanced_java
:star: *
:starline: *_
:starstar: **
:underscore: _
:toc: left
:backend: revealjs
:customcss: custom.css
:topic: state=title
:icons: font
:experimental:

== Lab 1: ArchUnit

. Open the _architectural-design-patterns_ project in GitPod
. In the _hex-arch_ module, and in the _src/test/java_ directory, and in the `com.jitterted.ebp.blackjack` package create a file called _HexArchTest.java_
. In the file, copy the following content
+
[source, java, subs="attributes,quotes,verbatim"]
----
package com.jitterted.ebp.blackjack;

import com.tngtech.archunit.core.domain.JavaClasses;
import com.tngtech.archunit.core.importer.ClassFileImporter;
import com.tngtech.archunit.lang.ArchRule;
import org.junit.jupiter.api.Test;

import static com.tngtech.archunit.lang.syntax.ArchRuleDefinition.noClasses;

public class HexArchTest {

  @Test
  public void domainMustNotDependOnAdapter() throws Exception {
    JavaClasses importedClasses =
        new ClassFileImporter().importPackages("com.jitterted.ebp.blackjack");

    ArchRule myRule = noClasses().that().resideInAPackage("..domain..")
                                 .should().dependOnClassesThat()
                                 .resideInAPackage("..adapter..");

    myRule.check(importedClasses);
  }
}
----
+
. Run the test in either your editor, or run it using `mvn test` in the command line.
. Does it violate our architectural rule?

image::stop.png[width="20%", height="20%", align="center"]

== Lab 2: Circuit Breaker

. In the _resilience4j_ module, in the _src/test/java_ directory, and in the `com.evolutionnext.resilience4j` package, open _CircuitBreakTest.java_
. Run the `TestCircuitBreaker` test and notice how it handles failure. In Gitpod do the following, so you can see the output:
.. `cd resilience4j`
.. `mvn test -Dtest=CircuitBreakerTest#testCircuitBreaker`
. Change order with the server of the output
. Try to change different settings in the `CircuitBreaker` and review the metrics

image::stop.png[width="20%", height="20%", align="center"]

== Lab 3: Retry

. In the _resilience4j_ module, in the _src/test/java_ directory, and in the `com.evolutionnext.resilience4j` package, open _RetryTest.java_
. Run the `testRetry` test and notice how it handles failure. In Gitpod do the following, so you can see the output:
.. `cd resilience4j`
.. `mvn test -Dtest=RetryTest#testRetry`
. Change order with the server of the output
. Try to change different settings in the `Retry` and review the metrics

image::stop.png[width="20%", height="20%", align="center"]

== Lab 4: Bulkhead

. In the _resilience4j_ module, in the _src/test/java_ directory, and in the _src/test/java_ directory, and in the `com.evolutionnext.resilience4j` package, open _BulkheadTest.java_
. Run the `testSemaphoreBulkhead` test and notice how it handles saturation. In Gitpod do the following, so you can see the output:
.. `cd resilience4j`
.. `mvn test -Dtest=BulkheadTest#testSemaphoreBulkhead`
. Try to change different settings in the `Bulkhead` and review the metrics
. Run the `testThreadPoolBulkhead` test and notice how it handles saturation. In Gitpod do the following, so you can see the output:
.. `cd resilience4j`
.. `mvn test -Dtest=BulkheadTest#testThreadPoolBulkhead`
. Try to change different settings in the `ThreadPoolBulkhead` and review the metrics

image::stop.png[width="20%", height="20%", align="center"]

== Lab 5: Competing Consumers

. Open the _competing-consumers_ module folder
. Right-click on the _docker-compose.yml_ file and select "Compose Up - Select Services", deselect all the checkmarks, and select `control-center`
. Wait until all the components are loaded that you can monitor with `docker ps`
. In your browser of choice, open port `9021` in your gitpod ports menu
+
image::control-center.png[]
+
. Next, click on the _Topics_ section on the left menu
. Click on _Add Topic_ button on the upper right hand corner
. In this new topic window, name the new topic _my-orders_ and enter `3` partitions
. Click the _Create with Defaults_ button
+
image::create-topic.png[]
+
. Go back to the _competing-consumers_ module folder
. Right-click on the _docker-compose.yml_ file and select "Compose Up - Select Services", deselect all the checkmarks, and just select `my-producer`, `my-consumer-1`, `my-consumer-2`, `my-consumer-3`
. View the logs of the running consumers by right-clicking on the container in the Docker menu and selecting "View Logs"
. Knock one of the consumers off by right-clicking one of the consumer containers, like `my-consumer-3` and select and view the logs of both `my-consumer-2` and `my-consumer-1`
. What do the logs say?
+
NOTE: In the logs, look for `Partitions Revoked` and `Partitions Assigned`. What you are looking for is a consumer picking up the slack of another consumer.
+
. Run `docker-compose down` in the _competing-consumers_ folder, by selecting the _docker_compose.yml_ file, right-clicking, and selecting "Compose Down"

image::stop.png[width="20%", height="20%", align="center"]

== Lab 6: Claim Check

. Navigate to your _architectural-design-patterns_ project and into the _claim-check_ module
. Right-click on the _docker-compose.yml_ file and select "Compose Up - Select Services", deselect all the checkmarks, and select `control-center`
. Wait until all the components are loaded
. In your browser of choice, open port `9021` in your gitpod ports menu
+
image::control-center.png[]
+
. Next, click on the _Topics_ section on the left menu
. Click on _Add Topic_ button on the upper right hand corner
. In this new topic window, name the new topic _my-avro-orders_ and enter `3` partitions
. Click the _Create with Defaults_ button
+
image::create-myavro-topic.png[]
+
. Navigate to your _architectural-design-patterns_ project and into the _claim-check_ module once again.
. Right-click on the _docker-compose.yml_ file and select "Compose Up - Select Services", deselect all the checkmarks, and select `my-avro-producer`, `my-avro-consumer-1`, `my-avro-consumer-2`, `my-avro-consumer-3`
. Open port 8081, from the ports menu in Gitpod. Visit `http://<gitpod-url>/subjects` and what do you see? Note one of the subjects, `my-avro-orders-value`
. Visit `http://<gitpod-url>/subjects/my-avro-orders-value/versions` and what do you see? Note the version number
. Visit `http://<gitpod-url>/subjects/my-avro-orders-value/versions/{versionId}` where you will replace `{versionId}` with the version you noted in the previous step. What do you see?
. The idea here is that there a schema involved, and you are looking at the storage, the claim check is the `id` you see in this payload. This schema is not sent with the message
. Run `docker-compose down` in the _claim-check_ module folder, by selecting the _docker_compose.yml_ file, right-clicking, and selecting "Compose Down"

image::stop.png[width="20%", height="20%", align="center"]

== Lab 7: CQRS (Command Query Responsibility Segregation)

=== Launch Initial Containers

. Open the _cqrs_ module folder
. Right-click on the _docker-compose.yml_ file and select "Compose Up - Select Services", deselect all the checkmarks, and select `connect ksqldb-cli postgres control-center`
. Login into `connect` container by using either `Attach Shell` on Gitpod or `docker exec -it connect /bin/bash`

=== Create a JDBC Connector

. Run the following in the container a JDBC Connect that reads from postgres - `confluent-hub install confluentinc/kafka-connect-jdbc:10.7.1`
. Select `2. / (where this tool is installed)`
. Answer `y` to `Do you want to install this into /usr/share/confluent-hub-components?`
. Answer `y` to `I agree to the software license agreement (yN)`
. Answer `y` to `Do you want to continue?`
. Answer `y` to `Do you want to update all detected configs? (yN)`

=== Create a MongoDB Connector

. Run the following in the container `confluent-hub install mongodb/kafka-connect-mongodb:1.10.0`, or whatever the latest version is from https://confluent.io/hub[Confluent Hub]
. Select `2. / (where this tool is installed)`
. Answer `y` to `Do you want to install this into /usr/share/confluent-hub-components?`
. Answer `y` to `I agree to the software license agreement (yN)`
. Answer `y` to `Do you want to continue?`
. Answer `y` to `Do you want to update all detected configs? (yN)`
. Exit the container using `exit`
. Restart the container in GitPod or using `docker restart connect`

=== Run the Data Generator

. Run the `CreateStocks` application by doing the following:
.. Create a new terminal
.. `cd cqrs`
.. Run `mvn clean compile exec:java -Dexec.mainClass=com.evolutionnext.cqrs.CreateStocks` to generate data.

=== View the Postgres Database

. Login into your `postgres` container using `Attach Shell` or `docker exec -it postgres /bin/bash`
. Run the following: `export PGPASSWORD='docker'`
. Run the following: `psql -d docker -U docker`
. In the Postgres shell run  `\dt` which will show all the tables
. In the Postgres shell run `\d stock_trade`, which will show specific table schema
. Run `SELECT * from stock_trade;` and ensure that the data exists
. Exit the `postgres` container by kbd:[CTRL+D] and typing `exit` in the shell

=== Create the Postgres Connector

. Log into the Confluent Control Center
. Select your cluster `controlcenter.cluster`
. Select _Connect_ in the menu
. Select the _connect_default_ cluster
. Select the btn:[Add Connector] button
. Select the btn:[JdbcSourceConnector] button
. Add the following in the respective fields:
.. *Key Converter Class* - `io.confluent.connect.avro.AvroConverter`
.. *Value Converter Class* - `io.confluent.connect.avro.AvroConverter`
.. *JDBC URL* - `jdbc:postgresql://postgres:5432/`
.. *JDBC User* - `docker`
.. *JDBC Pass* - `docker`
.. *Database Dialect* `PostgreSqlDatabaseDialect`
.. *Table Loading Mode* `incrementing`
.. *Topic Prefix* - `postgres_`
.. *Additional Properties* -  `key.converter.schema.registry.url` set to  `http://schema-registry:8081`
.. *Additional Properties* - `value.converter.schema.registry.url` set to `http://schema-registry:8081`
. Click btn:[Next]
. Verify the JSON output, then select btn:[Launch]
. Go back to the home page of the Confluent Control Center
. Go to the topics, and select _postgres_stock_trade_
. Select the _Messages_ menu
. View the data coming for data loading
. You can stop the database loading by initiating kbd:[CTRL+C]

=== Enrich the Data using KSQLDB


. Go to KSQL-CLI Container by either attaching to the `ksqldb-cli` shell using `docker exec ksqldb-cli /bin/bash`
. Run a ksql terminal that will attach to the KSQLDB Server using the following command
+
[source, sh, subs="attributes,quotes,verbatim"]
----
$ ksql http://ksqldb-server:8088
----
+
. In the KSQLDB CLI, Create a Stream
+
[source,ksql]
----
CREATE STREAM stock_trades WITH (
KAFKA_TOPIC = 'postgres_stock_trade',
VALUE_FORMAT = 'AVRO'
);
----
+
. Enter into the CLI the following:
+
[source,ksql]
----
SET 'auto.offset.reset'='earliest';
----
+
. Show the live data coming from the source
+
[source,ksql]
----
select * from STOCK_TRADES;
----
+
. Let's try something fancy, let's get a count of all the stocks and their count
+
[source,ksql]
----
select stock_symbol,count(*) as count from STOCK_TRADES group by STOCK_SYMBOL emit changes;
----
+
. Create an aggregate topic from the above statement
+
[source,ksql]
----
create table stock_count with (PARTITIONS = 3, VALUE_FORMAT = 'JSON') as select STOCK_SYMBOL, AS_VALUE(STOCK_SYMBOL) as symbol, count(*) as count from STOCK_TRADES group by stock_symbol EMIT CHANGES;
----

=== Create a MongoDB Sink

. Setup MongoDB sink (read data from Aggregate Topic and push data to MongoDB)
. Go back to the _Confluent Control Center_
. Click on the menu:Connect menu
. Click on the btn:[Upload connector config file] button
. Select the file from the _cqrs_ module _src/main./resources/mongosink.json_
. Click btn:[Next]
. Verify the JSON output, then select btn:[Launch]
. Open the browser to the `mongo-express` container using the admin username `admin` and password `pass`
. Locate the database _STOCK_COUNT_
. Locate the collection _stock_counts_
. Click btn:[View]

image::stop.png[width=15%, height=15%, align=center]
